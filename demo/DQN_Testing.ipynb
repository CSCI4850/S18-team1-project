{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Demo\n",
    "Just run through these to watch breakout run! We handle processing the frame input and rewards. We then make the environment and model then run the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci4850/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height and width\n",
    "INPUT_SHAPE = (84, 84)\n",
    "# frames used together to input (channels) into the convolutional model\n",
    "WINDOW_LENGTH = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atari Processor class for processing observations and rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtariProcessor():\n",
    "    \"\"\"\n",
    "    Atari Processor for processing \n",
    "    \"\"\"\n",
    "    def process_observation(self, observation):\n",
    "        assert observation.ndim == 3  # (height, width, channel)\n",
    "        img = Image.fromarray(observation)\n",
    "        img = img.resize(INPUT_SHAPE).convert('L')  # resize and convert to grayscale\n",
    "        processed_observation = np.array(img)\n",
    "        assert processed_observation.shape == INPUT_SHAPE\n",
    "        return processed_observation.astype('uint8')  # saves storage in experience memory\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        # We could perform this processing step in `process_observation`. In this case, however,\n",
    "        # we would need to store a `float32` array instead, which is 4x more memory intensive than\n",
    "        # an `uint8` array. This matters if we store 1M observations.\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gym Environment set up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Number of Actions: 3\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "processor = AtariProcessor()\n",
    "nb_actions = env.action_space.n-1\n",
    "print('Modified Number of Actions:', nb_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci4850/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (8, 8), strides=(4, 4))`\n",
      "  if sys.path[0] == '':\n",
      "/home/csci4850/lib/python3.5/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (4, 4), strides=(2, 2))`\n",
      "  \n",
      "/home/csci4850/lib/python3.5/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), strides=(1, 1))`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute_1 (Permute)          (None, 84, 84, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,685,667\n",
      "Trainable params: 1,685,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Next, we build our model. We use the same model that was described by Mnih et al. (2015).\n",
    "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
    "model = Sequential()\n",
    "if K.image_dim_ordering() == 'tf':\n",
    "    # (width, height, channels)\n",
    "    model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "elif K.image_dim_ordering() == 'th':\n",
    "    # (channels, width, height)\n",
    "    model.add(Permute((1, 2, 3), input_shape=input_shape))\n",
    "else:\n",
    "    raise RuntimeError('Unknown image_dim_ordering.')\n",
    "model.add(Convolution2D(32, 8, 8, subsample=(4, 4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 4, 4, subsample=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss='mse',optimizer=Adam(lr=0.00025))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the weights that you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_filename = 'breakout-v4-weights-18-04-27-18-28.h5'\n",
    "model.load_weights(weights_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the model and display the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd8488cdb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a frame set to 0s\n",
    "frames = np.zeros((1,WINDOW_LENGTH,)+INPUT_SHAPE)\n",
    "\n",
    "# reset the observation\n",
    "observation = env.reset()\n",
    "\n",
    "# process the first observation as an initial frame set\n",
    "myframe = processor.process_state_batch(processor.process_observation(observation))\n",
    "for i in range(WINDOW_LENGTH):\n",
    "    frames[:,i,:,:] = myframe\n",
    "    \n",
    "# show the observation initially\n",
    "plt.imshow(observation)\n",
    "clear_output(wait=True)\n",
    "display(plt.gcf())\n",
    "\n",
    "# initializers\n",
    "done = False\n",
    "iteration = 0\n",
    "\n",
    "# main loop\n",
    "while not done:\n",
    "    \n",
    "    # predict an action\n",
    "    action = np.argmax(model.predict(frames))\n",
    "    \n",
    "    # Eps-soft?\n",
    "    #if np.random.random() < 0.0:\n",
    "    #    action = np.random.randint(env.action_space.n)\n",
    "    \n",
    "    # modify the action space by adding one\n",
    "    modified_action = action+1\n",
    "    observation,reward,done,_ = env.step(modified_action)\n",
    "    \n",
    "    # process the frame\n",
    "    myframe = processor.process_state_batch(processor.process_observation(observation))\n",
    "    \n",
    "    # move the frame along\n",
    "    frames[:,0:WINDOW_LENGTH-1,:,:] = frames[:,1:WINDOW_LENGTH,:,:]\n",
    "    frames[:,WINDOW_LENGTH-1,:,:] = myframe\n",
    "    \n",
    "    # increment the iteration\n",
    "    iteration += 1\n",
    "    ## Skipping every 6th frame...\n",
    "    ## This can be changed, but slows the rendering in JLab...\n",
    "    if iteration % 6 == 0:\n",
    "        plt.imshow(observation)\n",
    "        clear_output(wait=True)\n",
    "        display(plt.gcf())\n",
    "\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
